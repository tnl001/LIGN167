{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_VERSION = 'v8'\n",
    "MODEL_VERSION = 'v11'\n",
    "\n",
    "DATA_ROOT = os.path.join('data', DATA_VERSION)\n",
    "MODEL_ROOT = os.path.join('model', MODEL_VERSION)\n",
    "\n",
    "TRAIN = os.path.join(DATA_ROOT, f'train.pkl')\n",
    "TEST = os.path.join(DATA_ROOT, f'test.pkl')\n",
    "WORD_IX = os.path.join(DATA_ROOT, f'word_ix.pkl')\n",
    "IX_WORD = os.path.join(DATA_ROOT, f'ix_word.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pickle.load(open(TRAIN, 'rb'))\n",
    "test = pickle.load(open(TEST, 'rb'))\n",
    "word_ix = pickle.load(open(WORD_IX, 'rb'))\n",
    "ix_word = pickle.load(open(IX_WORD, 'rb'))\n",
    "encoded_headlines = train + test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train:  8500\n",
      "length of test:  1500\n"
     ]
    }
   ],
   "source": [
    "print('length of train: ', len(train))\n",
    "print('length of test: ', len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General structure learned from PyTorch documentation\n",
    "class myLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, vocab_size, embedding_size):\n",
    "        super(myLSTM, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        \n",
    "        #self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, words):    \n",
    "        \n",
    "        h = torch.zeros(1, 1, self.hidden_size, requires_grad=False).to(device)\n",
    "        c = torch.zeros(1, 1, self.hidden_size, requires_grad=False).to(device)\n",
    "        \n",
    "        # embed words\n",
    "        w_embedding = self.embedding(words)\n",
    "        w_embedding = w_embedding.view(len(words), 1, self.embedding_size)\n",
    "\n",
    "        # run the lstm layer\n",
    "        output, (h, c) = self.lstm(w_embedding, (h, c))  \n",
    "        output = self.dropout(output)\n",
    "        result = self.linear(output)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 loss:  7.700089456782622 difference:  0\n",
      "epoch:  1 loss:  7.189630603229299 difference:  -0.510458853553323\n",
      "epoch:  2 loss:  6.993933383114197 difference:  -0.19569722011510127\n",
      "epoch:  3 loss:  6.859683897593442 difference:  -0.13424948552075566\n",
      "epoch:  4 loss:  6.736880642091527 difference:  -0.12280325550191495\n",
      "epoch:  5 loss:  6.617341567376081 difference:  -0.11953907471544589\n",
      "epoch:  6 loss:  6.5047290437782515 difference:  -0.11261252359782947\n",
      "epoch:  7 loss:  6.388451624673956 difference:  -0.11627741910429545\n",
      "epoch:  8 loss:  6.288012865066528 difference:  -0.1004387596074281\n",
      "epoch:  9 loss:  6.209832468187107 difference:  -0.07818039687942058\n",
      "epoch:  10 loss:  6.130764393301571 difference:  -0.07906807488553635\n",
      "epoch:  11 loss:  6.080481715679169 difference:  -0.050282677622401906\n",
      "epoch:  12 loss:  6.030985239491743 difference:  -0.04949647618742592\n",
      "epoch:  13 loss:  5.9850150026293365 difference:  -0.045970236862406644\n",
      "epoch:  14 loss:  5.952836924959631 difference:  -0.032178077669705374\n",
      "epoch:  15 loss:  5.91858045836056 difference:  -0.034256466599071445\n",
      "epoch:  16 loss:  5.908981592655182 difference:  -0.009598865705378046\n",
      "epoch:  17 loss:  5.872444604747436 difference:  -0.03653698790774573\n",
      "epoch:  18 loss:  5.853098655420191 difference:  -0.01934594932724476\n",
      "epoch:  19 loss:  5.838143895836438 difference:  -0.014954759583753585\n",
      "epoch:  20 loss:  5.805645564829602 difference:  -0.032498331006835635\n",
      "epoch:  21 loss:  5.784472542496289 difference:  -0.021173022333313085\n",
      "epoch:  22 loss:  5.770459768870298 difference:  -0.01401277362599096\n",
      "epoch:  23 loss:  5.74353432411306 difference:  -0.02692544475723757\n",
      "epoch:  24 loss:  5.718023221885457 difference:  -0.02551110222760311\n",
      "epoch:  25 loss:  5.695593018545824 difference:  -0.02243020333963308\n",
      "epoch:  26 loss:  5.664021624466952 difference:  -0.03157139407887222\n",
      "epoch:  27 loss:  5.652765685397036 difference:  -0.011255939069916288\n",
      "epoch:  28 loss:  5.624822077330421 difference:  -0.027943608066614445\n",
      "epoch:  29 loss:  5.602033265913234 difference:  -0.022788811417187027\n",
      "epoch:  30 loss:  5.571811972407733 difference:  -0.030221293505500846\n",
      "epoch:  31 loss:  5.554357724624522 difference:  -0.017454247783211585\n",
      "epoch:  32 loss:  5.534427030752687 difference:  -0.019930693871835103\n",
      "epoch:  33 loss:  5.514686781182009 difference:  -0.019740249570677548\n",
      "epoch:  34 loss:  5.493496715405408 difference:  -0.021190065776600875\n",
      "epoch:  35 loss:  5.472315377060105 difference:  -0.021181338345303224\n",
      "epoch:  36 loss:  5.459370218305027 difference:  -0.012945158755077735\n",
      "epoch:  37 loss:  5.441185299368466 difference:  -0.018184918936561267\n",
      "epoch:  38 loss:  5.425865231135313 difference:  -0.01532006823315335\n",
      "epoch:  39 loss:  5.406304935749839 difference:  -0.01956029538547366\n",
      "epoch:  40 loss:  5.3933524441228196 difference:  -0.012952491627019391\n",
      "epoch:  41 loss:  5.381041777842185 difference:  -0.012310666280634486\n",
      "epoch:  42 loss:  5.3661064967127405 difference:  -0.014935281129444533\n",
      "epoch:  43 loss:  5.358633577255642 difference:  -0.0074729194570988255\n",
      "epoch:  44 loss:  5.345439897242715 difference:  -0.01319368001292709\n",
      "epoch:  45 loss:  5.32921294614848 difference:  -0.016226951094234998\n",
      "epoch:  46 loss:  5.317363297862165 difference:  -0.011849648286314185\n",
      "epoch:  47 loss:  5.318557805173537 difference:  0.0011945073113714955\n",
      "epoch:  48 loss:  5.301934808085947 difference:  -0.016622997087590186\n",
      "epoch:  49 loss:  5.292426529744092 difference:  -0.009508278341854748\n"
     ]
    }
   ],
   "source": [
    "# in_size = max_len-1 # should be size of the inputting sentence/batch (how many words are being inputted)\n",
    "h_size = 128 # should be size of learned parameters\n",
    "out_size = len(word_ix) # should be size of vocab\n",
    "vocab_size = len(word_ix) # total unique words in corpus\n",
    "embed_size = 64 # dimension of each word's embedding\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "\n",
    "\n",
    "model = myLSTM(h_size, out_size, vocab_size, embed_size)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "losses = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    total_loss = 0\n",
    "     \n",
    "    for s in train:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # predict until the word right before the last word\n",
    "        predictions = model(torch.tensor(s, requires_grad=False)[:-1].to(device))    \n",
    "        \n",
    "        # loss = sent_loss(predictions, s).cpu()\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.squeeze(), torch.tensor(s, requires_grad=False)[1:].to(device)).cpu()\n",
    "        total_loss += loss.detach().numpy()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    avg_total_loss = total_loss / len(train)\n",
    "    losses.append(avg_total_loss)\n",
    "    diff = losses[i]-losses[i-1] if i > 0 else 0\n",
    "    print('epoch: ', i, 'loss: ', avg_total_loss, 'difference: ', diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2378a8b4f0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving models and trained parameters\n",
    "def saveModel(model, name, root, description):\n",
    "    model = model.cpu()\n",
    "    \n",
    "    if os.path.exists(root) == False:\n",
    "        os.makedirs(root)\n",
    "    \n",
    "    desc = open(os.path.join(root, 'description.txt'), 'w')\n",
    "    desc.write(description + '\\n')\n",
    "    desc.close()\n",
    "    \n",
    "    pickle.dump(model, open(name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToWord(s, ixw, wix):\n",
    "    res = ''\n",
    "    for w in s:\n",
    "        print(w)\n",
    "        res += ixw[w] + ' '\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(model, testSet, device, encoded_headlines):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for s in testSet:\n",
    "            \n",
    "            # predict until the word right before the last word\n",
    "            predictions = model(torch.tensor(s[:-1], requires_grad=False).to(device))\n",
    "            #pred = [np.argmax(predictions[i].cpu().detach().numpy()) for i in range(len(predictions))]\n",
    "            #print('predicted: ', pred, 'truth: ', s)\n",
    "            \n",
    "            loss = criterion(predictions.squeeze(), torch.tensor(s)[1:].to(device)).cpu()   \n",
    "            total_loss += loss.detach().numpy()\n",
    "            #print('loss: ', loss, 's: ', s)\n",
    "            \n",
    "        print('total_loss: ', total_loss)\n",
    "        print('len(testSet): ', len(testSet))\n",
    "        avg_total_loss = total_loss / len(testSet)\n",
    "\n",
    "        print('avg. loss on test set: ', avg_total_loss)\n",
    "    \n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSent(modelName, sentence, wordIndex):\n",
    "    # model = torch.load(modelName)\n",
    "    model = pickle.load(open(modelName, 'rb'))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    max_len = 5\n",
    "    sent_words = sentence.split()\n",
    "    encoded_sent = [word_ix['<START>']] + [word_ix[w] for w in sentence.split()]\n",
    "    \n",
    "    ix_word = defaultdict(str)\n",
    "    for w in wordIndex:\n",
    "        ix_word[wordIndex[w]] = w\n",
    "    \n",
    "    # predict until we reach the END signal\n",
    "    while True:\n",
    "        with torch.no_grad():\n",
    "            preds = model(torch.tensor(encoded_sent, requires_grad=False).to(device))\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        preds = softmax(preds.squeeze())\n",
    "        #print(torch.sum(preds[-1]))\n",
    "        pred_word = preds[-1].cpu().detach().numpy().tolist()\n",
    "        \n",
    "        pred_word = list(zip(pred_word, range(len(pred_word))))\n",
    "        pred_word.sort(reverse=True)\n",
    "        \n",
    "        \n",
    "        # randomly from the top k words to be the next word\n",
    "        k = 3\n",
    "        next_word = random.choice(pred_word[:k])\n",
    "        while len(encoded_sent) < max_len and next_word[1] == word_ix['<END>']:\n",
    "            next_word = random.choice(pred_word[:k])\n",
    "\n",
    "        #print(next_word)\n",
    "        encoded_sent.append(next_word[1])\n",
    "        \n",
    "        if len(encoded_sent) >= max_len and next_word[1] == word_ix['<END>']:\n",
    "            break\n",
    "        \n",
    "    # decode the sentence afterward\n",
    "    pred_sentence = [ix_word[i] for i in encoded_sent]\n",
    "    \n",
    "    model.train()\n",
    "    return pred_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = os.path.join(MODEL_ROOT, f'model.pkl')\n",
    "model_desc = f'{num_epochs} epochs, {len(train)} training size, {h_size} hidden size, {embed_size} embedding size, dropout=0.5'\n",
    "saveModel(model, model_name, MODEL_ROOT, model_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load('model_v4-50_epochs-8k-512h.pt')\n",
    "model = pickle.load(open(model_name, 'rb'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss:  16092.331322193146\n",
      "len(testSet):  1500\n",
      "avg. loss on test set:  10.728220881462097\n"
     ]
    }
   ],
   "source": [
    "testModel(model, test, device, encoded_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> car industry dies as us open in new <END>\n",
      "<START> car and the new help for us election and in <END>\n",
      "<START> car and the wa of the business <END>\n",
      "<START> car and the up of war against record says abc says <END>\n",
      "<START> car and the new health minister <END>\n",
      "<START> car and run in new west and to china in wa government to says a league the <END>\n",
      "<START> car crash and run <END>\n",
      "<START> car and run in new west to be held at the of man the death of police power on china <END>\n",
      "<START> car and top at world record day centre <END>\n",
      "<START> car industry dies in sydney murder <END>\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    sent = 'car'\n",
    "    pred = predictSent(model_name, sent, word_ix)\n",
    "    print(' '.join(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
