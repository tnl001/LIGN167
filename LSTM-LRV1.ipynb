{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_VERSION = 'v8'\n",
    "MODEL_VERSION = 'v12'\n",
    "\n",
    "DATA_ROOT = os.path.join('data', DATA_VERSION)\n",
    "MODEL_ROOT = os.path.join('model', MODEL_VERSION)\n",
    "\n",
    "TRAIN = os.path.join(DATA_ROOT, f'train.pkl')\n",
    "TEST = os.path.join(DATA_ROOT, f'test.pkl')\n",
    "WORD_IX = os.path.join(DATA_ROOT, f'word_ix.pkl')\n",
    "IX_WORD = os.path.join(DATA_ROOT, f'ix_word.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pickle.load(open(TRAIN, 'rb'))\n",
    "test = pickle.load(open(TEST, 'rb'))\n",
    "word_ix = pickle.load(open(WORD_IX, 'rb'))\n",
    "ix_word = pickle.load(open(IX_WORD, 'rb'))\n",
    "encoded_headlines = train + test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train:  8500\n",
      "length of test:  1500\n"
     ]
    }
   ],
   "source": [
    "print('length of train: ', len(train))\n",
    "print('length of test: ', len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General structure learned from PyTorch documentation\n",
    "class myLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, vocab_size, embedding_size):\n",
    "        super(myLSTM, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        \n",
    "        #self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, words):    \n",
    "        \n",
    "        h = torch.zeros(1, 1, self.hidden_size, requires_grad=False).to(device)\n",
    "        c = torch.zeros(1, 1, self.hidden_size, requires_grad=False).to(device)\n",
    "        \n",
    "        # embed words\n",
    "        w_embedding = self.embedding(words)\n",
    "        w_embedding = w_embedding.view(len(words), 1, self.embedding_size)\n",
    "\n",
    "        # run the lstm layer\n",
    "        output, (h, c) = self.lstm(w_embedding, (h, c))\n",
    "        result = self.linear(output)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 loss:  8.22020705297414 difference:  0\n",
      "epoch:  1 loss:  7.09029294480997 difference:  -1.1299141081641695\n",
      "epoch:  2 loss:  6.8050997900822585 difference:  -0.2851931547277111\n",
      "epoch:  3 loss:  6.687380392986185 difference:  -0.11771939709607349\n",
      "epoch:  4 loss:  6.694824649782742 difference:  0.007444256796556914\n",
      "epoch:  5 loss:  6.703078930868822 difference:  0.008254281086079729\n",
      "epoch:  6 loss:  6.853798908906825 difference:  0.15071997803800308\n",
      "epoch:  7 loss:  6.914204613755731 difference:  0.060405704848906616\n",
      "epoch:  8 loss:  6.833256079393275 difference:  -0.08094853436245675\n",
      "epoch:  9 loss:  6.8466851049872 difference:  0.013429025593925559\n",
      "epoch:  10 loss:  6.813155077176935 difference:  -0.03353002781026504\n",
      "epoch:  11 loss:  6.8008113235866325 difference:  -0.012343753590302597\n",
      "epoch:  12 loss:  6.8204552593792185 difference:  0.019643935792585943\n",
      "epoch:  13 loss:  6.809489327066085 difference:  -0.01096593231313392\n",
      "epoch:  14 loss:  6.83182544298733 difference:  0.02233611592124518\n",
      "epoch:  15 loss:  6.8453588705904345 difference:  0.01353342760310472\n",
      "epoch:  16 loss:  6.822311822610743 difference:  -0.02304704797969137\n",
      "epoch:  17 loss:  6.814367403563331 difference:  -0.007944419047412055\n",
      "epoch:  18 loss:  6.8587116058574 difference:  0.04434420229406921\n",
      "epoch:  19 loss:  6.844009581762202 difference:  -0.014702024095198496\n",
      "epoch:  20 loss:  6.828326812828289 difference:  -0.01568276893391296\n",
      "epoch:  21 loss:  6.808761478732614 difference:  -0.019565334095674736\n",
      "epoch:  22 loss:  6.810497477727778 difference:  0.0017359989951639676\n",
      "epoch:  23 loss:  6.8160365472961875 difference:  0.005539069568409438\n",
      "epoch:  24 loss:  6.860510004267973 difference:  0.04447345697178573\n",
      "epoch:  25 loss:  6.780070326131933 difference:  -0.08043967813603992\n",
      "epoch:  26 loss:  6.749971273927128 difference:  -0.030099052204805687\n",
      "epoch:  27 loss:  6.742348890837501 difference:  -0.007622383089626261\n",
      "epoch:  28 loss:  6.710664484977722 difference:  -0.03168440585977894\n",
      "epoch:  29 loss:  6.771299878358841 difference:  0.06063539338111834\n",
      "epoch:  30 loss:  6.714718908898971 difference:  -0.05658096945987001\n",
      "epoch:  31 loss:  6.711574219226837 difference:  -0.0031446896721334383\n",
      "epoch:  32 loss:  6.648747160126181 difference:  -0.06282705910065634\n",
      "epoch:  33 loss:  6.629688469185549 difference:  -0.01905869094063206\n",
      "epoch:  34 loss:  6.635208894449121 difference:  0.005520425263572548\n",
      "epoch:  35 loss:  6.7979056238286635 difference:  0.16269672937954205\n",
      "epoch:  36 loss:  6.800539821372313 difference:  0.0026341975436494636\n",
      "epoch:  37 loss:  6.615558739774367 difference:  -0.1849810815979458\n",
      "epoch:  38 loss:  6.600522869811338 difference:  -0.015035869963028858\n",
      "epoch:  39 loss:  6.564423783162061 difference:  -0.03609908664927719\n",
      "epoch:  40 loss:  6.562829178725972 difference:  -0.0015946044360894973\n",
      "epoch:  41 loss:  6.566604955645168 difference:  0.003775776919196616\n",
      "epoch:  42 loss:  6.533334111508201 difference:  -0.03327084413696735\n",
      "epoch:  43 loss:  6.511135634843041 difference:  -0.02219847666516017\n",
      "epoch:  44 loss:  6.494373868984335 difference:  -0.016761765858706035\n",
      "epoch:  45 loss:  6.49744322086783 difference:  0.0030693518834956635\n",
      "epoch:  46 loss:  6.454926957046284 difference:  -0.04251626382154594\n",
      "epoch:  47 loss:  6.440046335795347 difference:  -0.014880621250937587\n",
      "epoch:  48 loss:  6.426258960008621 difference:  -0.013787375786725953\n",
      "epoch:  49 loss:  6.415427721332101 difference:  -0.010831238676519916\n"
     ]
    }
   ],
   "source": [
    "# in_size = max_len-1 # should be size of the inputting sentence/batch (how many words are being inputted)\n",
    "h_size = 128 # should be size of learned parameters\n",
    "out_size = len(word_ix) # should be size of vocab\n",
    "vocab_size = len(word_ix) # total unique words in corpus\n",
    "embed_size = 64 # dimension of each word's embedding\n",
    "\n",
    "learning_rate = 0.01\n",
    "num_epochs = 50\n",
    "\n",
    "\n",
    "model = myLSTM(h_size, out_size, vocab_size, embed_size)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "losses = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    total_loss = 0\n",
    "     \n",
    "    for s in train:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # predict until the word right before the last word\n",
    "        predictions = model(torch.tensor(s, requires_grad=False)[:-1].to(device))    \n",
    "        \n",
    "        # loss = sent_loss(predictions, s).cpu()\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.squeeze(), torch.tensor(s, requires_grad=False)[1:].to(device)).cpu()\n",
    "        total_loss += loss.detach().numpy()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    avg_total_loss = total_loss / len(train)\n",
    "    losses.append(avg_total_loss)\n",
    "    diff = losses[i]-losses[i-1] if i > 0 else 0\n",
    "    print('epoch: ', i, 'loss: ', avg_total_loss, 'difference: ', diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9395dfa790>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving models and trained parameters\n",
    "def saveModel(model, name, root, description):\n",
    "    model = model.cpu()\n",
    "    \n",
    "    if os.path.exists(root) == False:\n",
    "        os.makedirs(root)\n",
    "    \n",
    "    desc = open(os.path.join(root, 'description.txt'), 'w')\n",
    "    desc.write(description + '\\n')\n",
    "    desc.close()\n",
    "    \n",
    "    pickle.dump(model, open(name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToWord(s, ixw, wix):\n",
    "    res = ''\n",
    "    for w in s:\n",
    "        print(w)\n",
    "        res += ixw[w] + ' '\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(model, testSet, device, encoded_headlines):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for s in testSet:\n",
    "            \n",
    "            # predict until the word right before the last word\n",
    "            predictions = model(torch.tensor(s[:-1], requires_grad=False).to(device))\n",
    "            #pred = [np.argmax(predictions[i].cpu().detach().numpy()) for i in range(len(predictions))]\n",
    "            #print('predicted: ', pred, 'truth: ', s)\n",
    "            \n",
    "            loss = criterion(predictions.squeeze(), torch.tensor(s)[1:].to(device)).cpu()   \n",
    "            total_loss += loss.detach().numpy()\n",
    "            #print('loss: ', loss, 's: ', s)\n",
    "            \n",
    "        print('total_loss: ', total_loss)\n",
    "        print('len(testSet): ', len(testSet))\n",
    "        avg_total_loss = total_loss / len(testSet)\n",
    "\n",
    "        print('avg. loss on test set: ', avg_total_loss)\n",
    "    \n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSent(modelName, sentence, wordIndex):\n",
    "    # model = torch.load(modelName)\n",
    "    model = pickle.load(open(modelName, 'rb'))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    max_len = 5\n",
    "    sent_words = sentence.split()\n",
    "    encoded_sent = [word_ix['<START>']] + [word_ix[w] for w in sentence.split()]\n",
    "    \n",
    "    ix_word = defaultdict(str)\n",
    "    for w in wordIndex:\n",
    "        ix_word[wordIndex[w]] = w\n",
    "    \n",
    "    # predict until we reach the END signal\n",
    "    while True:\n",
    "        with torch.no_grad():\n",
    "            preds = model(torch.tensor(encoded_sent, requires_grad=False).to(device))\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        preds = softmax(preds.squeeze())\n",
    "        #print(torch.sum(preds[-1]))\n",
    "        pred_word = preds[-1].cpu().detach().numpy().tolist()\n",
    "        \n",
    "        pred_word = list(zip(pred_word, range(len(pred_word))))\n",
    "        pred_word.sort(reverse=True)\n",
    "        \n",
    "        \n",
    "        # randomly from the top k words to be the next word\n",
    "        k = 3\n",
    "        next_word = random.choice(pred_word[:k])\n",
    "        while len(encoded_sent) < max_len and next_word[1] == word_ix['<END>']:\n",
    "            next_word = random.choice(pred_word[:k])\n",
    "\n",
    "        #print(next_word)\n",
    "        encoded_sent.append(next_word[1])\n",
    "        \n",
    "        if len(encoded_sent) >= max_len and next_word[1] == word_ix['<END>']:\n",
    "            break\n",
    "        \n",
    "    # decode the sentence afterward\n",
    "    pred_sentence = [ix_word[i] for i in encoded_sent]\n",
    "    \n",
    "    model.train()\n",
    "    return pred_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = os.path.join(MODEL_ROOT, f'model.pkl')\n",
    "model_desc = f'{num_epochs} epochs, {len(train)} training size, {h_size} hidden size, {embed_size} embedding size, dropout=0.3'\n",
    "saveModel(model, model_name, MODEL_ROOT, model_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load('model_v4-50_epochs-8k-512h.pt')\n",
    "model = pickle.load(open(model_name, 'rb'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss:  41167.36223125458\n",
      "len(testSet):  1500\n",
      "avg. loss on test set:  27.444908154169717\n"
     ]
    }
   ],
   "source": [
    "testModel(model, test, device, encoded_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> plane australia found on the australia to help <END>\n",
      "<START> plane australia shorten back in the police <END>\n",
      "<START> plane australia shorten scathing <END>\n",
      "<START> plane australian to help to the the police <END>\n",
      "<START> plane the the australia the australia police probe the australia the the the australia the police the australia police probe the police probe police officer september <END>\n",
      "<START> plane australian to the the police at australia government to be the the police station in the australia day years <END>\n",
      "<START> plane australia shorten back in <END>\n",
      "<START> plane the australia a australia a the police year <END>\n",
      "<START> plane australia found on police station to be australia to be the australia to the australia to the australia to help in wa at australia government to be police <END>\n",
      "<START> plane australia found in the police station <END>\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    sent = 'plane'\n",
    "    pred = predictSent(model_name, sent, word_ix)\n",
    "    print(' '.join(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
