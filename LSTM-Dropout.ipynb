{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_VERSION = 'v8'\n",
    "MODEL_VERSION = 'v9'\n",
    "\n",
    "DATA_ROOT = os.path.join('data', DATA_VERSION)\n",
    "MODEL_ROOT = os.path.join('model', MODEL_VERSION)\n",
    "\n",
    "TRAIN = os.path.join(DATA_ROOT, f'train.pkl')\n",
    "TEST = os.path.join(DATA_ROOT, f'test.pkl')\n",
    "WORD_IX = os.path.join(DATA_ROOT, f'word_ix.pkl')\n",
    "IX_WORD = os.path.join(DATA_ROOT, f'ix_word.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pickle.load(open(TRAIN, 'rb'))\n",
    "test = pickle.load(open(TEST, 'rb'))\n",
    "word_ix = pickle.load(open(WORD_IX, 'rb'))\n",
    "ix_word = pickle.load(open(IX_WORD, 'rb'))\n",
    "encoded_headlines = train + test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train:  8500\n",
      "length of test:  1500\n"
     ]
    }
   ],
   "source": [
    "print('length of train: ', len(train))\n",
    "print('length of test: ', len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General structure learned from PyTorch documentation\n",
    "class myLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, vocab_size, embedding_size):\n",
    "        super(myLSTM, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        \n",
    "        #self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, words):    \n",
    "        \n",
    "        h = torch.zeros(1, 1, self.hidden_size, requires_grad=False).to(device)\n",
    "        c = torch.zeros(1, 1, self.hidden_size, requires_grad=False).to(device)\n",
    "        \n",
    "        # embed words\n",
    "        w_embedding = self.embedding(words)\n",
    "        w_embedding = w_embedding.view(len(words), 1, self.embedding_size)\n",
    "\n",
    "        # run the lstm layer\n",
    "        output, (h, c) = self.lstm(w_embedding, (h, c))  \n",
    "        output = self.dropout(output)\n",
    "        result = self.linear(output)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 loss:  7.6639845438564524 difference:  0\n",
      "epoch:  1 loss:  7.011729007173987 difference:  -0.6522555366824658\n",
      "epoch:  2 loss:  6.711311985997592 difference:  -0.30041702117639435\n",
      "epoch:  3 loss:  6.433407591328901 difference:  -0.277904394668691\n",
      "epoch:  4 loss:  6.1700429408129525 difference:  -0.2633646505159488\n",
      "epoch:  5 loss:  5.917203027332531 difference:  -0.2528399134804218\n",
      "epoch:  6 loss:  5.703338821789798 difference:  -0.2138642055427331\n",
      "epoch:  7 loss:  5.522836843714995 difference:  -0.18050197807480295\n",
      "epoch:  8 loss:  5.370218721642214 difference:  -0.1526181220727807\n",
      "epoch:  9 loss:  5.2385973006486894 difference:  -0.13162142099352447\n",
      "epoch:  10 loss:  5.132812015175819 difference:  -0.10578528547287025\n",
      "epoch:  11 loss:  5.058000464839094 difference:  -0.07481155033672504\n",
      "epoch:  12 loss:  4.989880590060178 difference:  -0.06811987477891623\n",
      "epoch:  13 loss:  4.936391308475943 difference:  -0.05348928158423494\n",
      "epoch:  14 loss:  4.883080105234595 difference:  -0.05331120324134808\n",
      "epoch:  15 loss:  4.836951274703531 difference:  -0.04612883053106387\n",
      "epoch:  16 loss:  4.785698652772343 difference:  -0.05125262193118818\n",
      "epoch:  17 loss:  4.738726860614384 difference:  -0.04697179215795888\n",
      "epoch:  18 loss:  4.695034826587229 difference:  -0.04369203402715538\n",
      "epoch:  19 loss:  4.654216984377188 difference:  -0.04081784221004092\n",
      "epoch:  20 loss:  4.611690343464122 difference:  -0.04252664091306535\n",
      "epoch:  21 loss:  4.570886626748478 difference:  -0.040803716715644534\n",
      "epoch:  22 loss:  4.53225229473675 difference:  -0.0386343320117275\n",
      "epoch:  23 loss:  4.5031268098003725 difference:  -0.029125484936377788\n",
      "epoch:  24 loss:  4.468951814819785 difference:  -0.03417499498058785\n",
      "epoch:  25 loss:  4.429428113874267 difference:  -0.039523700945517604\n",
      "epoch:  26 loss:  4.400459150945439 difference:  -0.028968962928828113\n",
      "epoch:  27 loss:  4.362603486825438 difference:  -0.03785566412000119\n",
      "epoch:  28 loss:  4.331141609984286 difference:  -0.03146187684115187\n",
      "epoch:  29 loss:  4.311254503390368 difference:  -0.01988710659391746\n",
      "epoch:  30 loss:  4.284328967935899 difference:  -0.026925535454469518\n",
      "epoch:  31 loss:  4.264667049611316 difference:  -0.01966191832458275\n",
      "epoch:  32 loss:  4.238408780126011 difference:  -0.02625826948530552\n",
      "epoch:  33 loss:  4.212081799738548 difference:  -0.02632698038746284\n",
      "epoch:  34 loss:  4.187095883257249 difference:  -0.024985916481298887\n",
      "epoch:  35 loss:  4.174742202331038 difference:  -0.012353680926210586\n",
      "epoch:  36 loss:  4.155217266475453 difference:  -0.019524935855585568\n",
      "epoch:  37 loss:  4.139089626824155 difference:  -0.016127639651298153\n",
      "epoch:  38 loss:  4.1080366766382665 difference:  -0.03105295018588805\n",
      "epoch:  39 loss:  4.102340737931868 difference:  -0.005695938706398174\n",
      "epoch:  40 loss:  4.083021447118591 difference:  -0.019319290813277767\n",
      "epoch:  41 loss:  4.079292817024624 difference:  -0.003728630093966956\n",
      "epoch:  42 loss:  4.049189873456955 difference:  -0.03010294356766874\n",
      "epoch:  43 loss:  4.044888945397209 difference:  -0.004300928059746134\n",
      "epoch:  44 loss:  4.037468378691112 difference:  -0.0074205667060969205\n",
      "epoch:  45 loss:  4.012851455639391 difference:  -0.02461692305172125\n",
      "epoch:  46 loss:  4.009132664785666 difference:  -0.0037187908537248404\n",
      "epoch:  47 loss:  3.9907285757906297 difference:  -0.018404088995036094\n",
      "epoch:  48 loss:  3.976598223524935 difference:  -0.01413035226569459\n",
      "epoch:  49 loss:  3.964416565586539 difference:  -0.012181657938396206\n"
     ]
    }
   ],
   "source": [
    "# in_size = max_len-1 # should be size of the inputting sentence/batch (how many words are being inputted)\n",
    "h_size = 128 # should be size of learned parameters\n",
    "out_size = len(word_ix) # should be size of vocab\n",
    "vocab_size = len(word_ix) # total unique words in corpus\n",
    "embed_size = 64 # dimension of each word's embedding\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "\n",
    "\n",
    "model = myLSTM(h_size, out_size, vocab_size, embed_size)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "losses = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    total_loss = 0\n",
    "     \n",
    "    for s in train:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # predict until the word right before the last word\n",
    "        predictions = model(torch.tensor(s, requires_grad=False)[:-1].to(device))    \n",
    "        \n",
    "        # loss = sent_loss(predictions, s).cpu()\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.squeeze(), torch.tensor(s, requires_grad=False)[1:].to(device)).cpu()\n",
    "        total_loss += loss.detach().numpy()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    avg_total_loss = total_loss / len(train)\n",
    "    losses.append(avg_total_loss)\n",
    "    diff = losses[i]-losses[i-1] if i > 0 else 0\n",
    "    print('epoch: ', i, 'loss: ', avg_total_loss, 'difference: ', diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f03751b4520>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving models and trained parameters\n",
    "def saveModel(model, name, root, description):\n",
    "    model = model.cpu()\n",
    "    \n",
    "    if os.path.exists(root) == False:\n",
    "        os.makedirs(root)\n",
    "    \n",
    "    desc = open(os.path.join(root, 'description.txt'), 'w')\n",
    "    desc.write(description + '\\n')\n",
    "    desc.close()\n",
    "    \n",
    "    pickle.dump(model, open(name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToWord(s, ixw, wix):\n",
    "    res = ''\n",
    "    for w in s:\n",
    "        print(w)\n",
    "        res += ixw[w] + ' '\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(model, testSet, device, encoded_headlines):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for s in testSet:\n",
    "            \n",
    "            # predict until the word right before the last word\n",
    "            predictions = model(torch.tensor(s[:-1], requires_grad=False).to(device))\n",
    "            #pred = [np.argmax(predictions[i].cpu().detach().numpy()) for i in range(len(predictions))]\n",
    "            #print('predicted: ', pred, 'truth: ', s)\n",
    "            \n",
    "            loss = criterion(predictions.squeeze(), torch.tensor(s)[1:].to(device)).cpu()   \n",
    "            total_loss += loss.detach().numpy()\n",
    "            #print('loss: ', loss, 's: ', s)\n",
    "            \n",
    "        print('total_loss: ', total_loss)\n",
    "        print('len(testSet): ', len(testSet))\n",
    "        avg_total_loss = total_loss / len(testSet)\n",
    "\n",
    "        print('avg. loss on test set: ', avg_total_loss)\n",
    "    \n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSent(modelName, sentence, wordIndex):\n",
    "    # model = torch.load(modelName)\n",
    "    model = pickle.load(open(modelName, 'rb'))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    max_len = 5\n",
    "    sent_words = sentence.split()\n",
    "    encoded_sent = [word_ix['<START>']] + [word_ix[w] for w in sentence.split()]\n",
    "    \n",
    "    ix_word = defaultdict(str)\n",
    "    for w in wordIndex:\n",
    "        ix_word[wordIndex[w]] = w\n",
    "    \n",
    "    # predict until we reach the END signal\n",
    "    while True:\n",
    "        with torch.no_grad():\n",
    "            preds = model(torch.tensor(encoded_sent, requires_grad=False).to(device))\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        preds = softmax(preds.squeeze())\n",
    "        #print(torch.sum(preds[-1]))\n",
    "        pred_word = preds[-1].cpu().detach().numpy().tolist()\n",
    "        \n",
    "        pred_word = list(zip(pred_word, range(len(pred_word))))\n",
    "        pred_word.sort(reverse=True)\n",
    "        \n",
    "        \n",
    "        # randomly from the top k words to be the next word\n",
    "        k = 3\n",
    "        next_word = random.choice(pred_word[:k])\n",
    "        while len(encoded_sent) < max_len and next_word[1] == word_ix['<END>']:\n",
    "            next_word = random.choice(pred_word[:k])\n",
    "\n",
    "        #print(next_word)\n",
    "        encoded_sent.append(next_word[1])\n",
    "        \n",
    "        if len(encoded_sent) >= max_len and next_word[1] == word_ix['<END>']:\n",
    "            break\n",
    "        \n",
    "    # decode the sentence afterward\n",
    "    pred_sentence = [ix_word[i] for i in encoded_sent]\n",
    "    \n",
    "    model.train()\n",
    "    return pred_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = os.path.join(MODEL_ROOT, f'model.pkl')\n",
    "model_desc = f'{num_epochs} epochs, {len(train)} training size, {h_size} hidden size, {embed_size} embedding size, dropout=0.3'\n",
    "saveModel(model, model_name, MODEL_ROOT, model_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load('model_v4-50_epochs-8k-512h.pt')\n",
    "model = pickle.load(open(model_name, 'rb'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss:  15780.271886110306\n",
      "len(testSet):  1500\n",
      "avg. loss on test set:  10.52018125740687\n"
     ]
    }
   ],
   "source": [
    "testModel(model, test, device, encoded_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> car urges tax war crackdown in two <END>\n",
      "<START> car fatal defends left a good council <END>\n",
      "<START> car urges accident to community title <END>\n",
      "<START> car crash victims victims fire on pakistan from world <END>\n",
      "<START> car fatal down of australia river quake study says <END>\n",
      "<START> car fatal down over after site accident by <END>\n",
      "<START> car crash kills 10 years <END>\n",
      "<START> car fatal down after china faces another proposal peace of council on <END>\n",
      "<START> car crash kills three as iron first test <END>\n",
      "<START> car fatal down after china as nsw risk study farmers <END>\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    sent = 'car'\n",
    "    pred = predictSent(model_name, sent, word_ix)\n",
    "    print(' '.join(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
