{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_VERSION = 'v8'\n",
    "MODEL_VERSION = 'v8'\n",
    "\n",
    "DATA_ROOT = os.path.join('data', DATA_VERSION)\n",
    "MODEL_ROOT = os.path.join('model', MODEL_VERSION)\n",
    "\n",
    "TRAIN = os.path.join(DATA_ROOT, f'train.pkl')\n",
    "TEST = os.path.join(DATA_ROOT, f'test.pkl')\n",
    "WORD_IX = os.path.join(DATA_ROOT, f'word_ix.pkl')\n",
    "IX_WORD = os.path.join(DATA_ROOT, f'ix_word.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pickle.load(open(TRAIN, 'rb'))\n",
    "test = pickle.load(open(TEST, 'rb'))\n",
    "word_ix = pickle.load(open(WORD_IX, 'rb'))\n",
    "ix_word = pickle.load(open(IX_WORD, 'rb'))\n",
    "encoded_headlines = train + test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train:  8500\n",
      "length of test:  1500\n"
     ]
    }
   ],
   "source": [
    "print('length of train: ', len(train))\n",
    "print('length of test: ', len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General structure learned from PyTorch documentation\n",
    "class myLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, vocab_size, embedding_size):\n",
    "        super(myLSTM, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        \n",
    "        #self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, words):    \n",
    "        \n",
    "        h = torch.zeros(1, 1, self.hidden_size, requires_grad=False).to(device)\n",
    "        c = torch.zeros(1, 1, self.hidden_size, requires_grad=False).to(device)\n",
    "        \n",
    "        # embed words\n",
    "        w_embedding = self.embedding(words)\n",
    "        w_embedding = w_embedding.view(len(words), 1, self.embedding_size)\n",
    "\n",
    "        # run the lstm layer\n",
    "        output, (h, c) = self.lstm(w_embedding, (h, c))\n",
    "        result = self.linear(output)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 loss:  7.613543294570025 difference:  0\n",
      "epoch:  1 loss:  6.539339377024595 difference:  -1.0742039175454305\n",
      "epoch:  2 loss:  5.847812506072661 difference:  -0.6915268709519333\n",
      "epoch:  3 loss:  5.251382148399072 difference:  -0.5964303576735892\n",
      "epoch:  4 loss:  4.734093979484895 difference:  -0.5172881689141775\n",
      "epoch:  5 loss:  4.300923742588829 difference:  -0.43317023689606593\n",
      "epoch:  6 loss:  3.937722816895036 difference:  -0.3632009256937927\n",
      "epoch:  7 loss:  3.6383383909113265 difference:  -0.2993844259837095\n",
      "epoch:  8 loss:  3.389252810541321 difference:  -0.2490855803700054\n",
      "epoch:  9 loss:  3.167664522570722 difference:  -0.22158828797059904\n",
      "epoch:  10 loss:  2.985923453898991 difference:  -0.18174106867173112\n",
      "epoch:  11 loss:  2.835120372891426 difference:  -0.1508030810075649\n",
      "epoch:  12 loss:  2.690658264636993 difference:  -0.14446210825443284\n",
      "epoch:  13 loss:  2.590896346085212 difference:  -0.09976191855178129\n",
      "epoch:  14 loss:  2.49216466310445 difference:  -0.09873168298076207\n",
      "epoch:  15 loss:  2.405987677553121 difference:  -0.08617698555132902\n",
      "epoch:  16 loss:  2.3277358370528503 difference:  -0.07825184050027056\n",
      "epoch:  17 loss:  2.2886947173371035 difference:  -0.03904111971574675\n",
      "epoch:  18 loss:  2.2070278191461283 difference:  -0.08166689819097517\n",
      "epoch:  19 loss:  2.1363201030703154 difference:  -0.07070771607581294\n",
      "epoch:  20 loss:  2.079418844664798 difference:  -0.056901258405517297\n",
      "epoch:  21 loss:  2.0084992063045504 difference:  -0.07091963836024773\n",
      "epoch:  22 loss:  1.959494470294784 difference:  -0.04900473600976629\n",
      "epoch:  23 loss:  1.9204643910912906 difference:  -0.03903007920349344\n",
      "epoch:  24 loss:  1.8880181005562053 difference:  -0.0324462905350853\n",
      "epoch:  25 loss:  1.8635590376853943 difference:  -0.02445906287081101\n",
      "epoch:  26 loss:  1.8398707621167687 difference:  -0.023688275568625627\n",
      "epoch:  27 loss:  1.8037176357998568 difference:  -0.03615312631691192\n",
      "epoch:  28 loss:  1.7733975968220654 difference:  -0.03032003897779134\n",
      "epoch:  29 loss:  1.7649389805162654 difference:  -0.008458616305800026\n",
      "epoch:  30 loss:  1.7360554234560799 difference:  -0.028883557060185527\n",
      "epoch:  31 loss:  1.708720318177167 difference:  -0.027335105278912808\n",
      "epoch:  32 loss:  1.7165311652001212 difference:  0.007810847022954093\n",
      "epoch:  33 loss:  1.7068488917420892 difference:  -0.009682273458031965\n",
      "epoch:  34 loss:  1.6739525583491606 difference:  -0.032896333392928634\n",
      "epoch:  35 loss:  1.6675461098937427 difference:  -0.006406448455417824\n",
      "epoch:  36 loss:  1.6356754785565768 difference:  -0.031870631337165944\n",
      "epoch:  37 loss:  1.6386015669738545 difference:  0.0029260884172777057\n",
      "epoch:  38 loss:  1.6225793283616796 difference:  -0.01602223861217489\n",
      "epoch:  39 loss:  1.6251114130581126 difference:  0.002532084696432957\n",
      "epoch:  40 loss:  1.6114438153435202 difference:  -0.013667597714592361\n",
      "epoch:  41 loss:  1.618828721323434 difference:  0.007384905979913814\n",
      "epoch:  42 loss:  1.6027390644129584 difference:  -0.01608965691047559\n",
      "epoch:  43 loss:  1.6030932427013622 difference:  0.0003541782884037836\n",
      "epoch:  44 loss:  1.5612645011859783 difference:  -0.04182874151538396\n",
      "epoch:  45 loss:  1.5501084524182713 difference:  -0.011156048767706928\n",
      "epoch:  46 loss:  1.5506774981512743 difference:  0.0005690457330029819\n",
      "epoch:  47 loss:  1.5554739480860094 difference:  0.0047964499347350475\n",
      "epoch:  48 loss:  1.5718763693641213 difference:  0.016402421278111978\n",
      "epoch:  49 loss:  1.5458738880648333 difference:  -0.02600248129928806\n"
     ]
    }
   ],
   "source": [
    "# in_size = max_len-1 # should be size of the inputting sentence/batch (how many words are being inputted)\n",
    "h_size = 128 # should be size of learned parameters\n",
    "out_size = len(word_ix) # should be size of vocab\n",
    "vocab_size = len(word_ix) # total unique words in corpus\n",
    "embed_size = 64 # dimension of each word's embedding\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "\n",
    "\n",
    "model = myLSTM(h_size, out_size, vocab_size, embed_size)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "losses = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    total_loss = 0\n",
    "     \n",
    "    for s in train:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # predict until the word right before the last word\n",
    "        predictions = model(torch.tensor(s, requires_grad=False)[:-1].to(device))    \n",
    "        \n",
    "        # loss = sent_loss(predictions, s).cpu()\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.squeeze(), torch.tensor(s, requires_grad=False)[1:].to(device)).cpu()\n",
    "        total_loss += loss.detach().numpy()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    avg_total_loss = total_loss / len(train)\n",
    "    losses.append(avg_total_loss)\n",
    "    diff = losses[i]-losses[i-1] if i > 0 else 0\n",
    "    print('epoch: ', i, 'loss: ', avg_total_loss, 'difference: ', diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f83f91e24c0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving models and trained parameters\n",
    "def saveModel(model, name, root, description):\n",
    "    model = model.cpu()\n",
    "    \n",
    "    if os.path.exists(root) == False:\n",
    "        os.makedirs(root)\n",
    "    \n",
    "    desc = open(os.path.join(root, 'description.txt'), 'w')\n",
    "    desc.write(description + '\\n')\n",
    "    desc.close()\n",
    "    \n",
    "    pickle.dump(model, open(name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToWord(s, ixw, wix):\n",
    "    res = ''\n",
    "    for w in s:\n",
    "        print(w)\n",
    "        res += ixw[w] + ' '\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(model, testSet, device, encoded_headlines):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for s in testSet:\n",
    "            \n",
    "            # predict until the word right before the last word\n",
    "            predictions = model(torch.tensor(s[:-1], requires_grad=False).to(device))\n",
    "            #pred = [np.argmax(predictions[i].cpu().detach().numpy()) for i in range(len(predictions))]\n",
    "            #print('predicted: ', pred, 'truth: ', s)\n",
    "            \n",
    "            loss = criterion(predictions.squeeze(), torch.tensor(s)[1:].to(device)).cpu()   \n",
    "            total_loss += loss.detach().numpy()\n",
    "            #print('loss: ', loss, 's: ', s)\n",
    "            \n",
    "        print('total_loss: ', total_loss)\n",
    "        print('len(testSet): ', len(testSet))\n",
    "        avg_total_loss = total_loss / len(testSet)\n",
    "\n",
    "        print('avg. loss on test set: ', avg_total_loss)\n",
    "    \n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSent(modelName, sentence, wordIndex):\n",
    "    # model = torch.load(modelName)\n",
    "    model = pickle.load(open(modelName, 'rb'))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    max_len = 5\n",
    "    sent_words = sentence.split()\n",
    "    encoded_sent = [word_ix['<START>']] + [word_ix[w] for w in sentence.split()]\n",
    "    \n",
    "    ix_word = defaultdict(str)\n",
    "    for w in wordIndex:\n",
    "        ix_word[wordIndex[w]] = w\n",
    "    \n",
    "    # predict until we reach the END signal\n",
    "    while True:\n",
    "        with torch.no_grad():\n",
    "            preds = model(torch.tensor(encoded_sent, requires_grad=False).to(device))\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        preds = softmax(preds.squeeze())\n",
    "        #print(torch.sum(preds[-1]))\n",
    "        pred_word = preds[-1].cpu().detach().numpy().tolist()\n",
    "        \n",
    "        pred_word = list(zip(pred_word, range(len(pred_word))))\n",
    "        pred_word.sort(reverse=True)\n",
    "        \n",
    "        \n",
    "        # randomly from the top k words to be the next word\n",
    "        k = 3\n",
    "        next_word = random.choice(pred_word[:k])\n",
    "        while len(encoded_sent) < max_len and next_word[1] == word_ix['<END>']:\n",
    "            next_word = random.choice(pred_word[:k])\n",
    "\n",
    "        #print(next_word)\n",
    "        encoded_sent.append(next_word[1])\n",
    "        \n",
    "        if len(encoded_sent) >= max_len and next_word[1] == word_ix['<END>']:\n",
    "            break\n",
    "        \n",
    "    # decode the sentence afterward\n",
    "    pred_sentence = [ix_word[i] for i in encoded_sent]\n",
    "    \n",
    "    model.train()\n",
    "    return pred_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = os.path.join(MODEL_ROOT, f'model.pkl')\n",
    "model_desc = f'{num_epochs} epochs, {len(train)} training size, {h_size} hidden size, {embed_size} embedding size, dropout=0.3'\n",
    "saveModel(model, model_name, MODEL_ROOT, model_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load('model_v4-50_epochs-8k-512h.pt')\n",
    "model = pickle.load(open(model_name, 'rb'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss:  20860.629021286964\n",
      "len(testSet):  1500\n",
      "avg. loss on test set:  13.907086014191309\n"
     ]
    }
   ],
   "source": [
    "testModel(model, test, device, encoded_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> car war push on the market for australia begins defends problem <END>\n",
      "<START> car manufacturing dairy reporter a refugee people webber dies in inverell <END>\n",
      "<START> car manufacturing job losses to smr a open <END>\n",
      "<START> car crushes pedestrian to oil injured from schools <END>\n",
      "<START> car crushes pedestrian at hunter baby fishing found on migrant coast <END>\n",
      "<START> car war a education south east west voices concern <END>\n",
      "<START> car crushes about traditional world war to childrens australia <END>\n",
      "<START> car war urged in old delays heading <END>\n",
      "<START> car crushes about fire into fatal funding from state ashley <END>\n",
      "<START> car war urged to ahead with farming for nrl closer repairs <END>\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    sent = 'car'\n",
    "    pred = predictSent(model_name, sent, word_ix)\n",
    "    print(' '.join(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
