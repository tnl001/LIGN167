{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_VERSION = 'v9'\n",
    "MODEL_VERSION = 'v10'\n",
    "\n",
    "DATA_ROOT = os.path.join('data', DATA_VERSION)\n",
    "MODEL_ROOT = os.path.join('model', MODEL_VERSION)\n",
    "\n",
    "TRAIN = os.path.join(DATA_ROOT, f'train.pkl')\n",
    "TEST = os.path.join(DATA_ROOT, f'test.pkl')\n",
    "WORD_IX = os.path.join(DATA_ROOT, f'word_ix.pkl')\n",
    "IX_WORD = os.path.join(DATA_ROOT, f'ix_word.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pickle.load(open(TRAIN, 'rb'))\n",
    "test = pickle.load(open(TEST, 'rb'))\n",
    "word_ix = pickle.load(open(WORD_IX, 'rb'))\n",
    "ix_word = pickle.load(open(IX_WORD, 'rb'))\n",
    "encoded_headlines = train + test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train:  12750\n",
      "length of test:  2250\n"
     ]
    }
   ],
   "source": [
    "print('length of train: ', len(train))\n",
    "print('length of test: ', len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General structure learned from PyTorch documentation\n",
    "class myLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, vocab_size, embedding_size):\n",
    "        super(myLSTM, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        \n",
    "        #self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(embedding_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, words):    \n",
    "        \n",
    "        h = torch.zeros(1, 1, self.hidden_size, requires_grad=False).to(device)\n",
    "        c = torch.zeros(1, 1, self.hidden_size, requires_grad=False).to(device)\n",
    "        \n",
    "        # embed words\n",
    "        w_embedding = self.embedding(words)\n",
    "        w_embedding = w_embedding.view(len(words), 1, self.embedding_size)\n",
    "        #print('words: ', words.shape)\n",
    "        #print('words.view(1,-1): ', words.view(1,-1))\n",
    "        #print('words.squeeze: ', words.squeeze())\n",
    "        \n",
    "        #print('word_embedding: ', w_embedding)\n",
    "        #print('word_embedding size: \\n', w_embedding.size())\n",
    "        #print('word_embedding weight: \\n', self.embedding.weight)\n",
    "\n",
    "        # run the lstm layer\n",
    "        output, (h, c) = self.lstm(w_embedding, (h, c))  \n",
    "        output = self.dropout(output)\n",
    "        \n",
    "        result = self.linear(output)\n",
    "        #print('output shape: ', result.shape)\n",
    "        #print()\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 loss:  7.6959355128045175 difference:  0\n",
      "epoch:  1 loss:  7.08165715268079 difference:  -0.6142783601237278\n",
      "epoch:  2 loss:  6.8489077672023395 difference:  -0.23274938547845014\n",
      "epoch:  3 loss:  6.637190620141871 difference:  -0.21171714706046885\n",
      "epoch:  4 loss:  6.456321801391303 difference:  -0.18086881875056804\n",
      "epoch:  5 loss:  6.317538149992625 difference:  -0.13878365139867732\n",
      "epoch:  6 loss:  6.214871447338777 difference:  -0.10266670265384814\n",
      "epoch:  7 loss:  6.114320286746119 difference:  -0.10055116059265856\n",
      "epoch:  8 loss:  6.052441120409498 difference:  -0.06187916633662027\n",
      "epoch:  9 loss:  6.000667635216432 difference:  -0.051773485193066016\n",
      "epoch:  10 loss:  5.967773970286052 difference:  -0.032893664930380595\n",
      "epoch:  11 loss:  5.935306025056278 difference:  -0.03246794522977403\n",
      "epoch:  12 loss:  5.903716132294898 difference:  -0.0315898927613798\n",
      "epoch:  13 loss:  5.868356412840824 difference:  -0.03535971945407379\n",
      "epoch:  14 loss:  5.840400923373652 difference:  -0.02795548946717208\n",
      "epoch:  15 loss:  5.808475237869749 difference:  -0.031925685503902734\n",
      "epoch:  16 loss:  5.777678696884829 difference:  -0.030796540984920462\n",
      "epoch:  17 loss:  5.7405691569833195 difference:  -0.037109539901509336\n",
      "epoch:  18 loss:  5.701312731574563 difference:  -0.03925642540875618\n",
      "epoch:  19 loss:  5.666298081659804 difference:  -0.035014649914759666\n",
      "epoch:  20 loss:  5.630295557900971 difference:  -0.036002523758832616\n",
      "epoch:  21 loss:  5.60004008286607 difference:  -0.03025547503490067\n",
      "epoch:  22 loss:  5.566151042321149 difference:  -0.03388904054492148\n",
      "epoch:  23 loss:  5.538713829648261 difference:  -0.027437212672888123\n",
      "epoch:  24 loss:  5.510144351697436 difference:  -0.028569477950824762\n",
      "epoch:  25 loss:  5.483935576653948 difference:  -0.02620877504348762\n",
      "epoch:  26 loss:  5.4561953917344415 difference:  -0.027740184919506916\n",
      "epoch:  27 loss:  5.4316964620515416 difference:  -0.024498929682899906\n",
      "epoch:  28 loss:  5.410618336406409 difference:  -0.021078125645132673\n",
      "epoch:  29 loss:  5.376929749114841 difference:  -0.033688587291567984\n",
      "epoch:  30 loss:  5.359868681613137 difference:  -0.017061067501703775\n",
      "epoch:  31 loss:  5.338934442407945 difference:  -0.020934239205192107\n",
      "epoch:  32 loss:  5.3154267070340175 difference:  -0.023507735373927474\n",
      "epoch:  33 loss:  5.298827663655374 difference:  -0.016599043378643152\n",
      "epoch:  34 loss:  5.273720379464766 difference:  -0.025107284190608148\n",
      "epoch:  35 loss:  5.261304564027225 difference:  -0.012415815437541333\n",
      "epoch:  36 loss:  5.2398974062321235 difference:  -0.021407157795101384\n",
      "epoch:  37 loss:  5.223147969619901 difference:  -0.016749436612222723\n",
      "epoch:  38 loss:  5.2055642383846585 difference:  -0.01758373123524226\n",
      "epoch:  39 loss:  5.201612721078536 difference:  -0.003951517306122199\n",
      "epoch:  40 loss:  5.18874629501268 difference:  -0.012866426065856196\n",
      "epoch:  41 loss:  5.169657005665349 difference:  -0.019089289347331118\n",
      "epoch:  42 loss:  5.155106675297606 difference:  -0.014550330367742781\n",
      "epoch:  43 loss:  5.155210302708196 difference:  0.00010362741058944636\n",
      "epoch:  44 loss:  5.132043671682769 difference:  -0.023166631025426376\n",
      "epoch:  45 loss:  5.129246713582207 difference:  -0.0027969581005624633\n",
      "epoch:  46 loss:  5.118027299619189 difference:  -0.011219413963018177\n",
      "epoch:  47 loss:  5.10741558934193 difference:  -0.010611710277258268\n",
      "epoch:  48 loss:  5.095962773201513 difference:  -0.01145281614041771\n",
      "epoch:  49 loss:  5.080842963896545 difference:  -0.015119809304967369\n"
     ]
    }
   ],
   "source": [
    "# in_size = max_len-1 # should be size of the inputting sentence/batch (how many words are being inputted)\n",
    "h_size = 128 # should be size of learned parameters\n",
    "out_size = len(word_ix) # should be size of vocab\n",
    "vocab_size = len(word_ix) # total unique words in corpus\n",
    "embed_size = 64 # dimension of each word's embedding\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "\n",
    "\n",
    "model = myLSTM(h_size, out_size, vocab_size, embed_size)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "losses = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    total_loss = 0\n",
    "     \n",
    "    for s in train:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # predict until the word right before the last word\n",
    "        predictions = model(torch.tensor(s, requires_grad=False)[:-1].to(device))    \n",
    "        \n",
    "        # loss = sent_loss(predictions, s).cpu()\n",
    "        # print(predictions)\n",
    "        loss = criterion(predictions.squeeze(), torch.tensor(s, requires_grad=False)[1:].to(device)).cpu()\n",
    "        total_loss += loss.detach().numpy()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    avg_total_loss = total_loss / len(train)\n",
    "    losses.append(avg_total_loss)\n",
    "    diff = losses[i]-losses[i-1] if i > 0 else 0\n",
    "    print('epoch: ', i, 'loss: ', avg_total_loss, 'difference: ', diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4ad319b6d0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving models and trained parameters\n",
    "def saveModel(model, name, root, description):\n",
    "    model = model.cpu()\n",
    "    \n",
    "    if os.path.exists(root) == False:\n",
    "        os.makedirs(root)\n",
    "    \n",
    "    desc = open(os.path.join(root, 'description.txt'), 'w')\n",
    "    desc.write(description + '\\n')\n",
    "    desc.close()\n",
    "    \n",
    "    pickle.dump(model, open(name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToWord(s, ixw, wix):\n",
    "    res = ''\n",
    "    for w in s:\n",
    "        print(w)\n",
    "        res += ixw[w] + ' '\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(model, testSet, device, encoded_headlines):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        for s in testSet:\n",
    "            \n",
    "            # predict until the word right before the last word\n",
    "            predictions = model(torch.tensor(s[:-1], requires_grad=False).to(device))\n",
    "            #pred = [np.argmax(predictions[i].cpu().detach().numpy()) for i in range(len(predictions))]\n",
    "            #print('predicted: ', pred, 'truth: ', s)\n",
    "            \n",
    "            loss = criterion(predictions.squeeze(), torch.tensor(s)[1:].to(device)).cpu()   \n",
    "            total_loss += loss.detach().numpy()\n",
    "            #print('loss: ', loss, 's: ', s)\n",
    "            \n",
    "        print('total_loss: ', total_loss)\n",
    "        print('len(testSet): ', len(testSet))\n",
    "        avg_total_loss = total_loss / len(testSet)\n",
    "\n",
    "        print('avg. loss on test set: ', avg_total_loss)\n",
    "    \n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSent(modelName, sentence, wordIndex):\n",
    "    # model = torch.load(modelName)\n",
    "    model = pickle.load(open(modelName, 'rb'))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    max_len = 5\n",
    "    sent_words = sentence.split()\n",
    "    encoded_sent = [word_ix['<START>']] + [word_ix[w] for w in sentence.split()]\n",
    "    \n",
    "    ix_word = defaultdict(str)\n",
    "    for w in wordIndex:\n",
    "        ix_word[wordIndex[w]] = w\n",
    "    \n",
    "    # predict until we reach the END signal\n",
    "    while True:\n",
    "        with torch.no_grad():\n",
    "            preds = model(torch.tensor(encoded_sent, requires_grad=False).to(device))\n",
    "        softmax = nn.Softmax(dim=1)\n",
    "        preds = softmax(preds.squeeze())\n",
    "        #print(torch.sum(preds[-1]))\n",
    "        pred_word = preds[-1].cpu().detach().numpy().tolist()\n",
    "        \n",
    "        pred_word = list(zip(pred_word, range(len(pred_word))))\n",
    "        pred_word.sort(reverse=True)\n",
    "        \n",
    "        \n",
    "        # randomly from the top k words to be the next word\n",
    "        k = 3\n",
    "        next_word = random.choice(pred_word[:k])\n",
    "        while len(encoded_sent) < max_len and next_word[1] == word_ix['<END>']:\n",
    "            next_word = random.choice(pred_word[:k])\n",
    "\n",
    "        #print(next_word)\n",
    "        encoded_sent.append(next_word[1])\n",
    "        \n",
    "        if len(encoded_sent) >= max_len and next_word[1] == word_ix['<END>']:\n",
    "            break\n",
    "        \n",
    "    # decode the sentence afterward\n",
    "    pred_sentence = [ix_word[i] for i in encoded_sent]\n",
    "    \n",
    "    model.train()\n",
    "    return pred_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = os.path.join(MODEL_ROOT, f'model.pkl')\n",
    "model_desc = f'{num_epochs} epochs, {len(train)} training size, {h_size} hidden size, {embed_size} embedding size, dropout=0.3'\n",
    "saveModel(model, model_name, MODEL_ROOT, model_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load('model_v4-50_epochs-8k-512h.pt')\n",
    "model = pickle.load(open(model_name, 'rb'))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_loss:  21253.66663980484\n",
      "len(testSet):  2250\n",
      "avg. loss on test set:  9.446074062135484\n"
     ]
    }
   ],
   "source": [
    "testModel(model, test, device, encoded_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> plane crashes fall into adelaide meeting in <END>\n",
      "<START> plane makes emergency news in a <END>\n",
      "<START> plane makes emergency landing for warning on say <END>\n",
      "<START> plane crashes in nsw new zealand pm farmers <END>\n",
      "<START> plane crash death sparks of the woman <END>\n",
      "<START> plane crashes fall in car accident at <END>\n",
      "<START> plane crashes in new home buyers brisbane <END>\n",
      "<START> plane crashes into adelaide meeting with state of international <END>\n",
      "<START> plane makes free for child sex protection day of a day <END>\n",
      "<START> plane makes emergency in hospital set to pay a new final <END>\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    sent = 'plane'\n",
    "    pred = predictSent(model_name, sent, word_ix)\n",
    "    print(' '.join(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
